{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xb",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xb"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    }
   ],
   "source": [
    "import pandas_datareader.data as web\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import models, layers, optimizers\n",
    "import math\n",
    "from pytrends.request import TrendReq\n",
    "import pytrends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stock_bot(stock_name, comp_name, verbose=0, epochs=2000):\n",
    "    print(comp_name)\n",
    "    # ---- Read stock data and Google trends data.\n",
    "    start = datetime.today() - timedelta(370*5)\n",
    "    end = datetime.today() - timedelta(1)\n",
    "    df = web.DataReader(stock_name, 'iex', start, end)\n",
    "    stock = df.loc[:,'open']\n",
    "    num = len(stock)\n",
    "    \n",
    "    pytrends = TrendReq(hl='en-US', tz=300)\n",
    "    frame = df.index[0] + ' ' + df.index[-1]\n",
    "    pytrends.build_payload([comp_name], timeframe=frame, cat=0, geo='US')\n",
    "    search = pytrends.interest_over_time()\n",
    "    \n",
    "    # ---- Rescale trends data to be between -.5 and .5\n",
    "    trend_max = max(search.values[:,0])\n",
    "    trend_min = min(search.values[:,0])\n",
    "    trend_range = trend_max - trend_min\n",
    "    trend_med = trend_min + (trend_range / 2)\n",
    "    search_scaled = np.zeros((len(search.values)))\n",
    "    search_scaled = (search.values[:, 0] - trend_med) / trend_range\n",
    "    \n",
    "    # ---- Format input features as (day, trend value)\n",
    "    x = np.zeros((num, 2))\n",
    "    ind_cur = 0\n",
    "    trend_cur = search_scaled[ind_cur]\n",
    "    for i in range(len(x)):\n",
    "        x[i, 0] = (i / num) - .7\n",
    "        if (ind_cur < len(search_scaled) and search.index[ind_cur].year == int(df.index[i][:4]) and search.index[ind_cur].month == int(df.index[i][5:7]) and search.index[ind_cur].day <= int(df.index[i][8:])+2 and search.index[ind_cur].day >= int(df.index[i][8:])-2):\n",
    "            trend_cur = search_scaled[ind_cur]\n",
    "            ind_cur += 1\n",
    "        x[i, 1] = trend_cur\n",
    "    \n",
    "    # ---- Normalize stock data\n",
    "    y = stock\n",
    "    scaler = MinMaxScaler()\n",
    "    y = np.array(stock).reshape(len(stock), 1)\n",
    "    scaler = scaler.fit(y)\n",
    "    y = scaler.transform(y)\n",
    "    y = y.reshape(len(stock))\n",
    "    \n",
    "    # ---- Shuffle data\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "    y = y[shuffle_indices]\n",
    "    x = x[shuffle_indices]\n",
    "    \n",
    "    # ---- Construct network\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Dense(256, activation='relu', input_shape=(2,)))\n",
    "    network.add(layers.Dense(256, activation='relu'))\n",
    "    network.add(layers.Dense(256, activation='relu'))\n",
    "    network.add(layers.Dense(128, activation='relu'))\n",
    "    network.add(layers.Dense(128, activation='relu'))\n",
    "    network.add(layers.Dense(128, activation='relu'))\n",
    "    network.add(layers.Dense(64, activation='relu'))\n",
    "    network.add(layers.Dense(64, activation='relu'))\n",
    "    network.add(layers.Dense(64, activation='relu'))\n",
    "    network.add(layers.Dense(1))\n",
    "    \n",
    "    # ---- Compile and run network\n",
    "    network.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    history = network.fit(x, y, epochs=epochs, batch_size=50, verbose=verbose)\n",
    "    \n",
    "    # ---- Build test data set\n",
    "    xrange = 1400\n",
    "    x_test = np.zeros((xrange, 2))\n",
    "    ind_cur = 0\n",
    "    trend_cur = search_scaled[ind_cur]\n",
    "    for i in range(len(x_test)):\n",
    "        x_test[i, 0] = (i / num) - .7\n",
    "        if (ind_cur < len(search_scaled) and search.index[ind_cur].year == int(df.index[i][:4]) and search.index[ind_cur].month == int(df.index[i][5:7]) and search.index[ind_cur].day <= int(df.index[i][8:])+2 and search.index[ind_cur].day >= int(df.index[i][8:])-2):\n",
    "            trend_cur = search_scaled[ind_cur]\n",
    "            ind_cur += 1\n",
    "        x_test[i, 1] = trend_cur\n",
    "    y_pred = network.predict(x_test)\n",
    "    y_pred = scaler.inverse_transform(y_pred)[:,0]\n",
    "    \n",
    "    return num, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "companies_names = np.array(['Apple', 'Google', 'Microsoft', 'Amazon', 'Facebook', 'Berkshire Hathaway', 'Alibaba Group', \n",
    "                            'Johnson & Johnson', 'JPMorgan', 'ExxonMobil', 'Bank of America', 'Walmart', 'Wells Fargo', \n",
    "                            'Royal Dutch Shell', 'Visa', 'Procter & Gamble', 'Anheuser-Busch Inbev','AT&T', \n",
    "                            'Chevron Corporation', 'UnitedHealth Group', 'Pfizer', 'China Mobile', 'Home Depot', 'Intel', \n",
    "                            'Taiwan Semiconductor', 'Verizon Communications', 'Oracle Corporation', 'Citigroup',\n",
    "                            'Novartis'])\n",
    "companies_stocks = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'FB', 'BRK.A', 'BABA', 'JNJ', 'JPM', 'XOM', 'BAC', 'WMT', 'WFC', 'RDS.A', \n",
    "                    'V', 'PG', 'BUD', 'T', 'CVX', 'UNH', 'PFE', 'CHL', 'HD', 'INTC', 'TSM', 'VZ', 'ORCL', 'C', 'NVS']\n",
    "percent_returns = []\n",
    "\n",
    "for i in range(len(companies_names)):\n",
    "    num, prediction = stock_bot(companies_stocks[i], companies_names[i], epochs=10)\n",
    "    percent_change = (prediction[num+20] - prediction[num])/prediction[num]\n",
    "    percent_returns.append(percent_change)\n",
    "\n",
    "sort_ind = np.argsort(percent_returns)\n",
    "print('\\n\\n')\n",
    "print(companies_names[sort_ind][-3:])\n",
    "\n",
    "x = np.arange(len(companies_names))\n",
    "plt.bar(x, percent_returns)\n",
    "plt.xticks(x, companies_names, rotation=90)\n",
    "plt.savefig('returns.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
